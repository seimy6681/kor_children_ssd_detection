{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d50b6c3a",
   "metadata": {},
   "source": [
    "# 6.30.2025\n",
    "phoneme-level mixing augmentation\n",
    "음소 단위 mixing 오그멘테이션\n",
    "\n",
    "1) select DataFrame to generate (wdf) 단어 레벨 데이터셋의 human_text 칼럼을 mixing 해서 generation 합니다.\n",
    "2) 초성 종성 구분을 위해 human_text 를 초성 종성 구분하여 나누는 함수 decompose 를 불러 generation 할때 초성 종성을 각각 따로 가져옵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "78f711de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from jamo import hangul_to_jamo\n",
    "import hangul_jamo\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import os\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fe1f0099",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "08ba7584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# h2j 로 초성, 중성, 종성 구분있게 decompose 하기\n",
    "# return text in its decomposed string with chosung, jungsung and jongsung\n",
    "\n",
    "def decompose(text):\n",
    "    jamos = list(hangul_to_jamo(text))\n",
    "\n",
    "    # Prevent re-composition by adding | token in before, in-between, and after\n",
    "    decomposed = \"|\".join(jamos)\n",
    "    decomposed = \"|\" +decomposed + \"|\"\n",
    "    \n",
    "    # print(f'decompose: {decomposed}')\n",
    "        \n",
    "    return decomposed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3b4e08e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'|ㄸ|ᄄ|ᅡ|ᆯ|ᄀ|ᅵ|'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decompose('ㄸ딸기')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a654ea60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4356"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('ᄄ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3e3e379a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 레벨 데이터셋 로딩 (생성할 텍스트 칼럼이 있는 CSV)\n",
    "# orig_data = f'/data/selinawisco/kochild/nas_data/five_fold_datasets/test_fold_{fold}.csv'  # 트레인 셋 전체\n",
    "orig_data = f'/home/selinawisco/children_ssd_detection/augmentation/mixing_and_others/train_1_2_3_4_error_gen_fixed.csv'\n",
    "# orig_data = f'/data/selinawisco/kochild/nas_data/five_fold_datasets/test_fold_{fold}.csv'  \n",
    "# orig_data = f'/home/selinawisco/whisper_evals/whisper-small-fold{fold}-42-eval.csv' # transribed test file (fold_0_test 전사된 파일)\n",
    "\n",
    "wdf = pd.read_csv(orig_data)\n",
    "wdf['human_h2j'] =wdf['human_text'].apply(decompose)\n",
    "wdf['target_h2j'] =wdf['target_text'].apply(decompose)\n",
    "# wdf['asr_h2j'] =wdf['asr_human_transcription'].apply(decompose)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c0686e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3665"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0116d69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forced alignment 가 된 음소단위 데이터셋 불러오기 (학습데이터로 정렬한 데이터 !!)\n",
    "DATA = f\"/data/selinawisco/jamo_verified_folds_1_to_4/jamo_verified_fold_1_2_3_4.csv\"\n",
    "# DATA = f\"/data/selinawisco/kochild/forced_aligned/fold_0/human-aligned-fold-0-train/human_aligned_fold_{fold}_train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "45e1a76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0394ebcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fa_vocab =set(df['fa_phoneme_label'].unique())\n",
    "len(fa_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6d3dd167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 종성 초성 구분있게 다시 분리하기 위해서 다시 조합\n",
    "df['human_text'] = df['human_text_jamo'].apply(hangul_jamo.compose)\n",
    "df['target_text'] = df['target_text_jamo'].apply(hangul_jamo.compose)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ee506b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['human_h2j'] =df['human_text'].apply(decompose)\n",
    "df['target_h2j'] =df['target_text'].apply(decompose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "76d15a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[', ']', 'ㅄ', 'ㅒ', 'ㅖ', 'ㅙ', 'ㅚ', 'ㅢ', 'ㅣ'}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 초성 종성 구분 전 vocab 수:\n",
    "vocab1= set()\n",
    "for text in df['human_text_jamo']:\n",
    "    vocab1.update(jamo for jamo in text)\n",
    "fa_vocab^vocab1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6914b9b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'[',\n",
       " ']',\n",
       " '|',\n",
       " 'ᄀ',\n",
       " 'ᄁ',\n",
       " 'ᄂ',\n",
       " 'ᄃ',\n",
       " 'ᄄ',\n",
       " 'ᄅ',\n",
       " 'ᄆ',\n",
       " 'ᄇ',\n",
       " 'ᄈ',\n",
       " 'ᄉ',\n",
       " 'ᄊ',\n",
       " 'ᄋ',\n",
       " 'ᄌ',\n",
       " 'ᄍ',\n",
       " 'ᄎ',\n",
       " 'ᄏ',\n",
       " 'ᄐ',\n",
       " 'ᄑ',\n",
       " 'ᄒ',\n",
       " 'ᅡ',\n",
       " 'ᅢ',\n",
       " 'ᅣ',\n",
       " 'ᅤ',\n",
       " 'ᅥ',\n",
       " 'ᅦ',\n",
       " 'ᅧ',\n",
       " 'ᅨ',\n",
       " 'ᅩ',\n",
       " 'ᅪ',\n",
       " 'ᅫ',\n",
       " 'ᅬ',\n",
       " 'ᅭ',\n",
       " 'ᅮ',\n",
       " 'ᅯ',\n",
       " 'ᅱ',\n",
       " 'ᅲ',\n",
       " 'ᅳ',\n",
       " 'ᅴ',\n",
       " 'ᅵ',\n",
       " 'ᆨ',\n",
       " 'ᆩ',\n",
       " 'ᆫ',\n",
       " 'ᆮ',\n",
       " 'ᆯ',\n",
       " 'ᆷ',\n",
       " 'ᆸ',\n",
       " 'ᆹ',\n",
       " 'ᆺ',\n",
       " 'ᆼ',\n",
       " 'ᆽ',\n",
       " 'ᆾ',\n",
       " 'ㄱ',\n",
       " 'ㄲ',\n",
       " 'ㄴ',\n",
       " 'ㄷ',\n",
       " 'ㄸ',\n",
       " 'ㄹ',\n",
       " 'ㅁ',\n",
       " 'ㅂ',\n",
       " 'ㅃ',\n",
       " 'ㅅ',\n",
       " 'ㅆ',\n",
       " 'ㅇ',\n",
       " 'ㅈ',\n",
       " 'ㅉ',\n",
       " 'ㅊ',\n",
       " 'ㅋ',\n",
       " 'ㅌ',\n",
       " 'ㅍ',\n",
       " 'ㅎ',\n",
       " 'ㅏ',\n",
       " 'ㅐ',\n",
       " 'ㅑ',\n",
       " 'ㅓ',\n",
       " 'ㅔ',\n",
       " 'ㅕ',\n",
       " 'ㅗ',\n",
       " 'ㅘ',\n",
       " 'ㅛ',\n",
       " 'ㅜ',\n",
       " 'ㅝ',\n",
       " 'ㅟ',\n",
       " 'ㅠ',\n",
       " 'ㅡ'}"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 구분 후 vocab 수\n",
    "vocab = set()\n",
    "for text in df['human_h2j']:\n",
    "    vocab.update(jamo for jamo in text)\n",
    "fa_vocab ^ vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d0377198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46678"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2ab43124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'orig_audio', 'segment_audio', 'fa_phoneme_label',\n",
       "       'phoneme_idx', 'target_phoneme', 'human_phoneme', 'start_sample',\n",
       "       'end_sample', 'human_text_jamo', 'target_text_jamo', 'disease_type',\n",
       "       'age', 'gender', 'id', 'subgroup', 'phoneme_pred', 'human_text',\n",
       "       'target_text', 'human_h2j', 'target_h2j'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a243e7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n"
     ]
    }
   ],
   "source": [
    "# forced alignment phoneme label 이 중성 종성 초성 구분되게 다시 매핑\n",
    "\n",
    "def jamo_at_index(text, idx):\n",
    "\n",
    "    corrected_idx = 1 + idx * 2\n",
    "    decomposed = decompose(text)\n",
    "    # print(\"at index\", corrected_idx, \": \", decomposed[corrected_idx])\n",
    "    return decomposed[corrected_idx]\n",
    "\n",
    "print(df['fa_phoneme_label'].nunique())\n",
    "df['fa_phoneme_label_2'] = df.apply(lambda row: jamo_at_index(row['human_text'], row['phoneme_idx']), axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "89883f4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['fa_phoneme_label_2'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a8cb77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def jamo_from_decomposed(decomposed, orig_idx):\n",
    "#     corrected_idx= 1+orig_idx*2\n",
    "#     return decomposed[corrected_idx]\n",
    "\n",
    "# df['fa_phoneme_label_2'] = df.apply(lambda row: jamo_from_decomposed(row['human_h2j'], row['phoneme_idx']), axis=1)\n",
    "# s2 = set(df['fa_phoneme_label_2'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e12a47d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s2)\n",
    "len(s2-fa_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "f180032e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phoneme_mixing(df, input_text, target_text, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 셔플\n",
    "    np.random.seed(1)\n",
    "    df = df.sample(frac=1)\n",
    "    input_orig = input_text # 분리전 텍스트 저장\n",
    "    input_text = decompose(input_text.strip()) # 초종성 유지하며 분리\n",
    "    sdf = df[df['target_text']==target_text] # 타겟 단어만 필터 \n",
    "    \n",
    "    mixed_data = []\n",
    "    \n",
    "    jamo_paths = [] # list of phoneme paths to concatenate\n",
    "    jamo_audios = []\n",
    "    \n",
    "    for i in range(1,len(input_text),2):\n",
    "        \n",
    "        jamo = input_text[i]\n",
    "        # print(jamo)\n",
    "        candidates = sdf[sdf['fa_phoneme_label_2']==jamo] # 먼저 타겟단어 안에서 자모 가져오기\n",
    "        if len(candidates) > 1: \n",
    "            jamo_path = candidates.sample(n=1).iloc[0]['segment_audio']\n",
    "            jamo_audio, sr = librosa.load(jamo_path, sr=16000)\n",
    "            \n",
    "            jamo_paths.append(jamo_path)\n",
    "            jamo_audios.append(jamo_audio)\n",
    "        else: # 해당 타겟단어안에서 음소가 없으면 전체에서 가져오기\n",
    "            # print(\"jamo not found in target text\")\n",
    "            all_candidates = df[df['fa_phoneme_label_2']==jamo]\n",
    "            # print(ord(df[df['fa_phoneme_label']]))\n",
    "            # print(ord(jamo))\n",
    "            if len(all_candidates) == 0:\n",
    "                # Skip this input_text because one phoneme is missing\n",
    "                print(f\"Skipping '{input_orig}' — no match for jamo '{jamo}({ord(jamo)})'\")\n",
    "                return []  # or continue to next input_text in a loop, if applicable\n",
    "\n",
    "            jamo_path = all_candidates.sample(n=1).iloc[0]['segment_audio'] \n",
    "            jamo_paths.append(jamo_path)\n",
    "            \n",
    "            jamo_audio, sr = librosa.load(jamo_path, sr=16000)\n",
    "            jamo_audios.append(jamo_audio)\n",
    "            \n",
    "    output = np.concatenate(jamo_audios)\n",
    "    output_path = os.path.join(output_dir, f\"phoneme_mixing_{input_text}.wav\")\n",
    "    sf.write(output_path, output, sr)\n",
    "    \n",
    "    # csv entries\n",
    "    mixed_data.append({\n",
    "        \"audio\": output_path,\n",
    "        \"target_text\": target_text,\n",
    "        \"human_text\": input_orig,\n",
    "        \"human_text_decomposed\": input_text,\n",
    "    })\n",
    "    \n",
    "    return mixed_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed37a5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phoneme_mixing_age(df, input_text, target_text, age, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # 셔플\n",
    "    np.random.seed(1)\n",
    "    df = df.sample(frac=1)\n",
    "    input_orig = input_text # 분리전 텍스트 저장\n",
    "    input_text = decompose(input_text.strip()) # 초종성 유지하며 분리\n",
    "    sdf = df[df['target_text']==target_text] # 타겟 단어만 필터 \n",
    "    \n",
    "    mixed_data = []\n",
    "    \n",
    "    jamo_paths = [] # list of phoneme paths to concatenate\n",
    "    jamo_audios = []\n",
    "    \n",
    "    for i in range(1,len(input_text),2):\n",
    "        \n",
    "        jamo = input_text[i]\n",
    "        # print(jamo)\n",
    "        jamo_candidates = sdf[sdf['fa_phoneme_label_2']==jamo] # 먼저 타겟단어 안에서 자모 가져오기\n",
    "        candidates = jamo_candidates[jamo_candidates['age']==age]\n",
    "        \n",
    "        if len(candidates) > 1: \n",
    "            jamo_path = candidates.sample(n=1).iloc[0]['segment_audio']\n",
    "            jamo_audio, sr = librosa.load(jamo_path, sr=16000)\n",
    "            \n",
    "            jamo_paths.append(jamo_path)\n",
    "            jamo_audios.append(jamo_audio)\n",
    "        else: # 해당 타겟단어안에서 음소가 없으면 전체에서 가져오기\n",
    "            # print(\"jamo not found in target text\")\n",
    "            all_jamo_candidates = df[df['fa_phoneme_label_2']==jamo]\n",
    "            all_candidates = all_jamo_candidates[all_jamo_candidates['age']==age]\n",
    "            \n",
    "            if len(all_candidates) == 0:\n",
    "                # Skip this input_text because one phoneme is missing\n",
    "                print(f\"Skipping '{input_orig}' — no match for jamo '{jamo}({ord(jamo)})'\")\n",
    "                return []  # or continue to next input_text in a loop, if applicable\n",
    "\n",
    "            jamo_path = all_candidates.sample(n=1).iloc[0]['segment_audio'] \n",
    "            jamo_paths.append(jamo_path)\n",
    "            \n",
    "            jamo_audio, sr = librosa.load(jamo_path, sr=16000)\n",
    "            jamo_audios.append(jamo_audio)\n",
    "            \n",
    "    output = np.concatenate(jamo_audios)\n",
    "    output_path = os.path.join(output_dir, f\"phoneme_mixing_{input_text}.wav\")\n",
    "    sf.write(output_path, output, sr)\n",
    "    \n",
    "    # csv entries\n",
    "    mixed_data.append({\n",
    "        \"audio\": output_path,\n",
    "        \"target_text\": target_text,\n",
    "        \"human_text\": input_orig,\n",
    "        \"human_text_decomposed\": input_text,\n",
    "    })\n",
    "    \n",
    "    return mixed_data\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c65a78",
   "metadata": {},
   "source": [
    "나이 안에서 믹싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fe6f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 나이 고려\n",
    "\n",
    "# # 발음 틀린 음성만 생성하기\n",
    "swdf = wdf[wdf['new_label']==1]\n",
    "\n",
    "# wdf = wdf.head(5) \n",
    "tqdm.pandas()\n",
    "\n",
    "csv_used_name = pathlib.Path(orig_data).stem\n",
    "print(\"CSV used to generate human_texts (word level) \", csv_used_name)\n",
    "\n",
    "print(\"phoneme segments used to mix are from \",pathlib.Path(DATA) )\n",
    "phonemes_from = pathlib.Path(DATA).stem\n",
    "\n",
    "# 음성 저장할 경로\n",
    "output_dir = f\"/data/selinawisco/phoneme_mixing/mixed_{csv_used_name}_from_{phonemes_from}_age--\"\n",
    "mixed_data_all = list(chain.from_iterable(\n",
    "    swdf.progress_apply(lambda row: phoneme_mixing_age(df, row['human_text'], row['target_text'], row['age'], output_dir=output_dir), axis=1)\n",
    "))\n",
    "print(\"mixed audio saved to \", output_dir)\n",
    "\n",
    "mixed_df = pd.DataFrame(mixed_data_all)\n",
    "mixed_df.to_csv(f'{output_dir}/{csv_used_name}_age.csv', index=False)\n",
    "\n",
    "print(\"mixed audio CSV saved to \", f'{output_dir}/{csv_used_name}_from {phonemes_from}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcba6eb6",
   "metadata": {},
   "source": [
    "오발음만 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a0132a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 발음 틀린 음성만 생성하기\n",
    "wdf = wdf[wdf['new_label']==1]\n",
    "\n",
    "# wdf = wdf.head(5) \n",
    "tqdm.pandas()\n",
    "\n",
    "csv_used_name = pathlib.Path(orig_data).stem\n",
    "print(\"CSV used to generate human_texts (word level) \", csv_used_name)\n",
    "\n",
    "print(\"phoneme segments used to mix are from \",pathlib.Path(DATA) )\n",
    "phonemes_from = pathlib.Path(DATA).stem\n",
    "\n",
    "# 음성 저장할 경로\n",
    "output_dir = f\"/data/selinawisco/phoneme_mixing/mixed_{csv_used_name}_from_verified_{phonemes_from}_fixed\"\n",
    "mixed_data_all = list(chain.from_iterable(\n",
    "    wdf.progress_apply(lambda row: phoneme_mixing(df, row['human_text'], row['target_text'], output_dir=output_dir), axis=1)\n",
    "))\n",
    "print(\"mixed audio saved to \", output_dir)\n",
    "\n",
    "mixed_df = pd.DataFrame(mixed_data_all)\n",
    "mixed_df.to_csv(f'{output_dir}/{csv_used_name}.csv', index=False)\n",
    "\n",
    "print(\"mixed audio CSV saved to \", f'{output_dir}/{csv_used_name}_from {phonemes_from}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b363e973",
   "metadata": {},
   "source": [
    "정발음만 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6bc147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV used to generate human_texts (word level)  test_fold_0\n",
      "phoneme segments used to mix are from  /data/selinawisco/kochild/forced_aligned/fold_0/human-aligned-fold-0-train/human_aligned_fold_0_train.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2587/2587 [01:35<00:00, 27.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mixed audio saved to  /data/selinawisco/phoneme_mixing/mixed_test_fold_0_correct_v1\n",
      "mixed audio CSV saved to  /data/selinawisco/phoneme_mixing/mixed_test_fold_0_correct_v1/test_fold_0_correct_v1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 발음 맞춘 음성만 생성하기\n",
    "wdf = wdf[wdf['new_label']==0]\n",
    "\n",
    "# wdf = wdf.head(5) \n",
    "tqdm.pandas()\n",
    "\n",
    "csv_used_name = pathlib.Path(orig_data).stem\n",
    "print(\"CSV used to generate human_texts (word level) \", csv_used_name)\n",
    "\n",
    "print(\"phoneme segments used to mix are from \",pathlib.Path(DATA) )\n",
    "\n",
    "# 음성 저장할 경로\n",
    "output_dir = f\"/data/selinawisco/phoneme_mixing/mixed_{csv_used_name}_correct_v1\"\n",
    "mixed_data_all = list(chain.from_iterable(\n",
    "    wdf.progress_apply(lambda row: phoneme_mixing(df, row['human_text'], row['target_text'], output_dir=output_dir), axis=1)\n",
    "))\n",
    "print(\"mixed audio saved to \", output_dir)\n",
    "\n",
    "mixed_df = pd.DataFrame(mixed_data_all)\n",
    "mixed_df.to_csv(f'{output_dir}/{csv_used_name}_correct_v1.csv', index=False)\n",
    "\n",
    "print(\"mixed audio CSV saved to \", f'{output_dir}/{csv_used_name}_correct_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfa7b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'audio': './phoneme_mixing/phoneme_mixing_|ᄒ|ᅩ|ᄅ|ᅡ|ᆼ|ᄋ|ᅵ|.wav',\n",
       "  'target_text': '호랑이',\n",
       "  'human_text': '|ᄒ|ᅩ|ᄅ|ᅡ|ᆼ|ᄋ|ᅵ|'}]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # sample run: 데이터셋에 없는 텍스트 만들어보기\n",
    "# phoneme_mixing(df, input_text=\"호랑이\",target_text= \"호랑이\", output_dir=\"./phoneme_mixing\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e71434",
   "metadata": {},
   "source": [
    "기존 train file 과 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ef1fc945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fold 0 train + mixed 합치기\n",
    "mixed = pd.read_csv(f'/data/selinawisco/phoneme_mixing/mixed_train_1_2_3_4_error_gen_fixed_from_verified_jamo_verified_fold_1_2_3_4_fixed/train_1_2_3_4_error_gen_fixed.csv')\n",
    "orig_train = pd.read_csv(f'/data/selinawisco/kochild/five_fold_datasets/test_fold_{fold}_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "db400e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['audio', 'disease_type', 'age', 'gender', 'subgroup', 'id',\n",
       "       'textgrid_text', 'target_text', 'human_text', 'asr_text',\n",
       "       'target_text_jamo', 'human_text_jamo', 'new_label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "c503d203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['audio', 'target_text', 'human_text', 'human_text_decomposed'], dtype='object')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b91356d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_train = orig_train.drop(columns=['disease_type', 'age', 'gender', 'subgroup', 'id',\n",
    "       'textgrid_text', 'asr_text',\n",
    "       'target_text_jamo', 'new_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "09c7c9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed = mixed.drop(columns=[\"human_text_decomposed\"])\n",
    "mixed['human_text_jamo'] = mixed['human_text'].apply(hangul_jamo.decompose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "3b5e7102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>target_text</th>\n",
       "      <th>human_text</th>\n",
       "      <th>human_text_jamo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/data/selinawisco/phoneme_mixing/mixed_train_1...</td>\n",
       "      <td>눈사람</td>\n",
       "      <td>눈사암</td>\n",
       "      <td>ㄴㅜㄴㅅㅏㅇㅏㅁ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/data/selinawisco/phoneme_mixing/mixed_train_1...</td>\n",
       "      <td>눈사람</td>\n",
       "      <td>눈다암</td>\n",
       "      <td>ㄴㅜㄴㄷㅏㅇㅏㅁ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/data/selinawisco/phoneme_mixing/mixed_train_1...</td>\n",
       "      <td>장갑</td>\n",
       "      <td>상갑</td>\n",
       "      <td>ㅅㅏㅇㄱㅏㅂ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/data/selinawisco/phoneme_mixing/mixed_train_1...</td>\n",
       "      <td>눈사람</td>\n",
       "      <td>눈사란</td>\n",
       "      <td>ㄴㅜㄴㅅㅏㄹㅏㄴ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/data/selinawisco/phoneme_mixing/mixed_train_1...</td>\n",
       "      <td>눈사람</td>\n",
       "      <td>눈따란</td>\n",
       "      <td>ㄴㅜㄴㄸㅏㄹㅏㄴ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117</th>\n",
       "      <td>/data/selinawisco/phoneme_mixing/mixed_train_1...</td>\n",
       "      <td>눈사람</td>\n",
       "      <td>눈타랑</td>\n",
       "      <td>ㄴㅜㄴㅌㅏㄹㅏㅇ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118</th>\n",
       "      <td>/data/selinawisco/phoneme_mixing/mixed_train_1...</td>\n",
       "      <td>햄버거</td>\n",
       "      <td>햄러거</td>\n",
       "      <td>ㅎㅐㅁㄹㅓㄱㅓ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>/data/selinawisco/phoneme_mixing/mixed_train_1...</td>\n",
       "      <td>바퀴</td>\n",
       "      <td>빠퀴</td>\n",
       "      <td>ㅃㅏㅋㅟ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2120</th>\n",
       "      <td>/data/selinawisco/phoneme_mixing/mixed_train_1...</td>\n",
       "      <td>바퀴</td>\n",
       "      <td>빠휘</td>\n",
       "      <td>ㅃㅏㅎㅟ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>/data/selinawisco/phoneme_mixing/mixed_train_1...</td>\n",
       "      <td>꽃</td>\n",
       "      <td>꽁</td>\n",
       "      <td>ㄲㅗㅇ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2122 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  audio target_text  \\\n",
       "0     /data/selinawisco/phoneme_mixing/mixed_train_1...         눈사람   \n",
       "1     /data/selinawisco/phoneme_mixing/mixed_train_1...         눈사람   \n",
       "2     /data/selinawisco/phoneme_mixing/mixed_train_1...          장갑   \n",
       "3     /data/selinawisco/phoneme_mixing/mixed_train_1...         눈사람   \n",
       "4     /data/selinawisco/phoneme_mixing/mixed_train_1...         눈사람   \n",
       "...                                                 ...         ...   \n",
       "2117  /data/selinawisco/phoneme_mixing/mixed_train_1...         눈사람   \n",
       "2118  /data/selinawisco/phoneme_mixing/mixed_train_1...         햄버거   \n",
       "2119  /data/selinawisco/phoneme_mixing/mixed_train_1...          바퀴   \n",
       "2120  /data/selinawisco/phoneme_mixing/mixed_train_1...          바퀴   \n",
       "2121  /data/selinawisco/phoneme_mixing/mixed_train_1...           꽃   \n",
       "\n",
       "     human_text human_text_jamo  \n",
       "0           눈사암        ㄴㅜㄴㅅㅏㅇㅏㅁ  \n",
       "1           눈다암        ㄴㅜㄴㄷㅏㅇㅏㅁ  \n",
       "2            상갑          ㅅㅏㅇㄱㅏㅂ  \n",
       "3           눈사란        ㄴㅜㄴㅅㅏㄹㅏㄴ  \n",
       "4           눈따란        ㄴㅜㄴㄸㅏㄹㅏㄴ  \n",
       "...         ...             ...  \n",
       "2117        눈타랑        ㄴㅜㄴㅌㅏㄹㅏㅇ  \n",
       "2118        햄러거         ㅎㅐㅁㄹㅓㄱㅓ  \n",
       "2119         빠퀴            ㅃㅏㅋㅟ  \n",
       "2120         빠휘            ㅃㅏㅎㅟ  \n",
       "2121          꽁             ㄲㅗㅇ  \n",
       "\n",
       "[2122 rows x 4 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0f468c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>target_text</th>\n",
       "      <th>human_text</th>\n",
       "      <th>human_text_jamo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/data/selinawisco/kochild/APAC/일반아동/일반_clear/1...</td>\n",
       "      <td>빨대</td>\n",
       "      <td>빨대</td>\n",
       "      <td>ㅃㅏㄹㄷㅐ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/data/selinawisco/kochild/APAC/일반아동/일반_clear/1...</td>\n",
       "      <td>사탕</td>\n",
       "      <td>사탕</td>\n",
       "      <td>ㅅㅏㅌㅏㅇ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/data/selinawisco/kochild/APAC/일반아동/일반_clear/1...</td>\n",
       "      <td>침대</td>\n",
       "      <td>침대</td>\n",
       "      <td>ㅊㅣㅁㄷㅐ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/data/selinawisco/kochild/APAC/일반아동/일반_clear/1...</td>\n",
       "      <td>꽃</td>\n",
       "      <td>꽃</td>\n",
       "      <td>ㄲㅗㅊ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/data/selinawisco/kochild/APAC/일반아동/일반_clear/1...</td>\n",
       "      <td>바퀴</td>\n",
       "      <td>바퀴</td>\n",
       "      <td>ㅂㅏㅋㅟ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16939</th>\n",
       "      <td>/data/selinawisco/kochild/K_APP/구개열아동/KAPP낱말/2...</td>\n",
       "      <td>눈</td>\n",
       "      <td>뉴</td>\n",
       "      <td>ㄴㅠ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16940</th>\n",
       "      <td>/data/selinawisco/kochild/K_APP/구개열아동/KAPP낱말/2...</td>\n",
       "      <td>쨈</td>\n",
       "      <td>떄이</td>\n",
       "      <td>ㄸㅒㅇㅣ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16941</th>\n",
       "      <td>/data/selinawisco/kochild/K_APP/구개열아동/KAPP낱말/2...</td>\n",
       "      <td>쨈</td>\n",
       "      <td>떄이</td>\n",
       "      <td>ㄸㅒㅇㅣ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16942</th>\n",
       "      <td>/data/selinawisco/kochild/K_APP/구개열아동/KAPP낱말/2...</td>\n",
       "      <td>총</td>\n",
       "      <td>툥</td>\n",
       "      <td>ㅌㅛㅇ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16943</th>\n",
       "      <td>/data/selinawisco/kochild/K_APP/구개열아동/KAPP낱말/2...</td>\n",
       "      <td>똥</td>\n",
       "      <td>녀</td>\n",
       "      <td>ㄴㅕ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16944 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   audio target_text  \\\n",
       "0      /data/selinawisco/kochild/APAC/일반아동/일반_clear/1...          빨대   \n",
       "1      /data/selinawisco/kochild/APAC/일반아동/일반_clear/1...          사탕   \n",
       "2      /data/selinawisco/kochild/APAC/일반아동/일반_clear/1...          침대   \n",
       "3      /data/selinawisco/kochild/APAC/일반아동/일반_clear/1...           꽃   \n",
       "4      /data/selinawisco/kochild/APAC/일반아동/일반_clear/1...          바퀴   \n",
       "...                                                  ...         ...   \n",
       "16939  /data/selinawisco/kochild/K_APP/구개열아동/KAPP낱말/2...           눈   \n",
       "16940  /data/selinawisco/kochild/K_APP/구개열아동/KAPP낱말/2...           쨈   \n",
       "16941  /data/selinawisco/kochild/K_APP/구개열아동/KAPP낱말/2...           쨈   \n",
       "16942  /data/selinawisco/kochild/K_APP/구개열아동/KAPP낱말/2...           총   \n",
       "16943  /data/selinawisco/kochild/K_APP/구개열아동/KAPP낱말/2...           똥   \n",
       "\n",
       "      human_text human_text_jamo  \n",
       "0             빨대           ㅃㅏㄹㄷㅐ  \n",
       "1             사탕           ㅅㅏㅌㅏㅇ  \n",
       "2             침대           ㅊㅣㅁㄷㅐ  \n",
       "3              꽃             ㄲㅗㅊ  \n",
       "4             바퀴            ㅂㅏㅋㅟ  \n",
       "...          ...             ...  \n",
       "16939          뉴              ㄴㅠ  \n",
       "16940         떄이            ㄸㅒㅇㅣ  \n",
       "16941         떄이            ㄸㅒㅇㅣ  \n",
       "16942          툥             ㅌㅛㅇ  \n",
       "16943          녀              ㄴㅕ  \n",
       "\n",
       "[16944 rows x 4 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "70ee51d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>target_text</th>\n",
       "      <th>human_text</th>\n",
       "      <th>human_text_jamo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/data/selinawisco/kochild/APAC/일반아동/일반_clear/1...</td>\n",
       "      <td>빨대</td>\n",
       "      <td>빨대</td>\n",
       "      <td>ㅃㅏㄹㄷㅐ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/data/selinawisco/kochild/APAC/일반아동/일반_clear/1...</td>\n",
       "      <td>사탕</td>\n",
       "      <td>사탕</td>\n",
       "      <td>ㅅㅏㅌㅏㅇ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/data/selinawisco/kochild/APAC/일반아동/일반_clear/1...</td>\n",
       "      <td>침대</td>\n",
       "      <td>침대</td>\n",
       "      <td>ㅊㅣㅁㄷㅐ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/data/selinawisco/kochild/APAC/일반아동/일반_clear/1...</td>\n",
       "      <td>꽃</td>\n",
       "      <td>꽃</td>\n",
       "      <td>ㄲㅗㅊ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/data/selinawisco/kochild/APAC/일반아동/일반_clear/1...</td>\n",
       "      <td>바퀴</td>\n",
       "      <td>바퀴</td>\n",
       "      <td>ㅂㅏㅋㅟ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2117</th>\n",
       "      <td>/data/selinawisco/phoneme_mixing/mixed_train_1...</td>\n",
       "      <td>눈사람</td>\n",
       "      <td>눈타랑</td>\n",
       "      <td>ㄴㅜㄴㅌㅏㄹㅏㅇ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2118</th>\n",
       "      <td>/data/selinawisco/phoneme_mixing/mixed_train_1...</td>\n",
       "      <td>햄버거</td>\n",
       "      <td>햄러거</td>\n",
       "      <td>ㅎㅐㅁㄹㅓㄱㅓ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>/data/selinawisco/phoneme_mixing/mixed_train_1...</td>\n",
       "      <td>바퀴</td>\n",
       "      <td>빠퀴</td>\n",
       "      <td>ㅃㅏㅋㅟ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2120</th>\n",
       "      <td>/data/selinawisco/phoneme_mixing/mixed_train_1...</td>\n",
       "      <td>바퀴</td>\n",
       "      <td>빠휘</td>\n",
       "      <td>ㅃㅏㅎㅟ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>/data/selinawisco/phoneme_mixing/mixed_train_1...</td>\n",
       "      <td>꽃</td>\n",
       "      <td>꽁</td>\n",
       "      <td>ㄲㅗㅇ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19066 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  audio target_text  \\\n",
       "0     /data/selinawisco/kochild/APAC/일반아동/일반_clear/1...          빨대   \n",
       "1     /data/selinawisco/kochild/APAC/일반아동/일반_clear/1...          사탕   \n",
       "2     /data/selinawisco/kochild/APAC/일반아동/일반_clear/1...          침대   \n",
       "3     /data/selinawisco/kochild/APAC/일반아동/일반_clear/1...           꽃   \n",
       "4     /data/selinawisco/kochild/APAC/일반아동/일반_clear/1...          바퀴   \n",
       "...                                                 ...         ...   \n",
       "2117  /data/selinawisco/phoneme_mixing/mixed_train_1...         눈사람   \n",
       "2118  /data/selinawisco/phoneme_mixing/mixed_train_1...         햄버거   \n",
       "2119  /data/selinawisco/phoneme_mixing/mixed_train_1...          바퀴   \n",
       "2120  /data/selinawisco/phoneme_mixing/mixed_train_1...          바퀴   \n",
       "2121  /data/selinawisco/phoneme_mixing/mixed_train_1...           꽃   \n",
       "\n",
       "     human_text human_text_jamo  \n",
       "0            빨대           ㅃㅏㄹㄷㅐ  \n",
       "1            사탕           ㅅㅏㅌㅏㅇ  \n",
       "2            침대           ㅊㅣㅁㄷㅐ  \n",
       "3             꽃             ㄲㅗㅊ  \n",
       "4            바퀴            ㅂㅏㅋㅟ  \n",
       "...         ...             ...  \n",
       "2117        눈타랑        ㄴㅜㄴㅌㅏㄹㅏㅇ  \n",
       "2118        햄러거         ㅎㅐㅁㄹㅓㄱㅓ  \n",
       "2119         빠퀴            ㅃㅏㅋㅟ  \n",
       "2120         빠휘            ㅃㅏㅎㅟ  \n",
       "2121          꽁             ㄲㅗㅇ  \n",
       "\n",
       "[19066 rows x 4 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented = pd.concat([orig_train, mixed])\n",
    "augmented # 1464 + 16944\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "6994ca55",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented.to_csv('/data/selinawisco/kochild/five_fold_datasets_with_phoneme_mixing/train_fold_0_and_train_1_2_3_4_error_gen_fixed.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fcd8f0",
   "metadata": {},
   "source": [
    "정발음 믹싱음성도 불러와 같이 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0252020b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21653\n"
     ]
    }
   ],
   "source": [
    "#정상음성도 포함\n",
    "mdf = pd.read_csv('/data/selinawisco/phoneme_mixing/mixed_train_1_2_3_4_error_gen_fixed_from_verified_jamo_verified_fold_1_2_3_4_fixed/train_1_2_3_4_error_gen_fixed.csv')\n",
    "mdf = mdf.drop(columns=[\"human_text_decomposed\"])\n",
    "mdf['human_text_jamo'] = mdf['human_text'].apply(hangul_jamo.decompose)\n",
    "cdf = pd.read_csv('/data/selinawisco/phoneme_mixing/mixed_test_fold_0_correct_v1/test_fold_0_correct_v1.csv')\n",
    "cdf = cdf.drop(columns=[\"human_text_decomposed\"])\n",
    "cdf['human_text_jamo'] = cdf['human_text'].apply(hangul_jamo.decompose)\n",
    "\n",
    "result = pd.concat([mdf,cdf])\n",
    "result_final = pd.concat([orig_train,result])\n",
    "print(len(result_final))\n",
    "result_final.to_csv('/data/selinawisco/phoneme_mixing/train_fold_0_and_mixed_train_1_2_3_4_error_gen_fixed_verified_and_correct_v1.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
