{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "chunked_data_df : 단어 레벨 데이터프레임\n",
    "train_concat_df : 발화자 레벨 데이터프레임 (발화자 ID 추출 때 사용됨)\n",
    "label : TD/SSD (0/1) to augment (클래스 0과 1에 대해서 각각 함수 호출)\n",
    "num_concat : 음성 하나에 붙일 단어샘플 수\n",
    "\n",
    "'''\n",
    "def audio_augment_by_label(chunked_data_df, train_concat_df, label, num_concat, st_index):\n",
    "    \n",
    "    #filter out the necessary rows for augmentation\n",
    "    train_concat_df =train_concat_df[train_concat_df['disease_type']==label] # TD 나 SSD\n",
    "    train_spkrs = train_concat_df['id'].unique().tolist() # Extract all train speakers\n",
    "    train_data_df = chunked_data_df[chunked_data_df['id'].isin(train_spkrs)] #Extract all chunked data spoken by the speakers in train_concat_df\n",
    "\n",
    "    train_grouped_df = train_data_df.groupby('age') # group the train data dataframe by age\n",
    "    new_path_prefix = f\"/home/selinawisco/whisper/data/kochild/augmented_{num_concat}\"\n",
    "\n",
    "    proc = 0 # to keep track of how many augmented audio were produced\n",
    "    new_speaker_id = st_index # starting index of the file name\n",
    "    inc = 0 #increment variable for filename\n",
    "    \n",
    "    #shuffle each grouped by age df in train_grouped_df\n",
    "    shuffled_dfs = [] # list to store all the shuffled df by age\n",
    "    for age,age_df in train_grouped_df:\n",
    "\n",
    "        shuffled_df = age_df.sample(frac=1).reset_index(drop=True) #shuffle the df\n",
    "        # total_groups = total_groups + (len(shuffled_df) // 5 + 1)\n",
    "        shuffled_dfs.append(shuffled_df) #add the shuffled age df to the list of shuffled dfs\n",
    "\n",
    "    #--------- dictionary for csv file ---------\n",
    "    data_dict = {\n",
    "                'audio': [],\n",
    "                'disease_type': [],\n",
    "                'age': [],\n",
    "                'id': []\n",
    "            }\n",
    "    #-------------------------------------------\n",
    "    \n",
    "    for shuffled_df in shuffled_dfs:\n",
    "\n",
    "        #grabbing the universal information for this df for csv creation\n",
    "        #-----------------------csv------------------------------\n",
    "        curr_age = shuffled_df['age'][0]\n",
    "        curr_label = shuffled_df['disease_type'][0]\n",
    "        #-----------------------csv------------------------------\n",
    "\n",
    "        if(len(shuffled_df) % num_concat == 0):\n",
    "            num_groups = len(shuffled_df) // num_concat\n",
    "        else: # if there's a remainder after dividing by num_concat\n",
    "            num_groups = len(shuffled_df) // num_concat + 1\n",
    "        # Inside a specific age df, looping over the number of groups\n",
    "        for i in range(num_groups):   \n",
    "\n",
    "            #getting the num_concat amount of audio in a dataframe called group \n",
    "            group = pd.DataFrame(shuffled_df.loc[i*num_concat : (i+1)*num_concat])\n",
    "            full_audio_data, sr = librosa.load(group.loc[group.index[0], 'audio'], sr=None) #loading the first in the group\n",
    "\n",
    "            #>>>>>Concatenation of the audios in group<<<<<<#\n",
    "            for j in range(1, len(group)):\n",
    "\n",
    "                audio_data, _ = librosa.load(group.loc[group.index[j], 'audio'], sr=sr)\n",
    "                full_audio_data = np.concatenate((full_audio_data, audio_data))\n",
    "            \n",
    "            inc = inc + 1\n",
    "            #-------------------- create audio ----------------------------\n",
    "           \n",
    "            new_path = \"%s/%d\"%(new_path_prefix, new_speaker_id + inc)\n",
    "            os.makedirs(new_path, exist_ok=True)\n",
    "            soundfile.write(\"%s/combined_speech.wav\"%new_path,full_audio_data,sr,format=\"wav\") # create the augmented audio\n",
    "            proc = proc + 1\n",
    "            #-------------------- create audio -----------------------------\n",
    "\n",
    "            #------------------------- csv ---------------------------\n",
    "            # add augmented audio info to csv file\n",
    "\n",
    "            data_dict['speech_file'].append(\"%s/combined_speech.wav\"%new_path)\n",
    "            data_dict['age'].append(curr_age)\n",
    "            data_dict['id'].append(new_speaker_id + inc)\n",
    "            data_dict['disease_type'].append(curr_label)\n",
    "            #------------------------- csv ---------------------------\n",
    "\n",
    "    new_df = pd.DataFrame.from_dict(data_dict)\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_level_df = pd.read_csv(DATA_PATH + 'r08.1_train.csv')\n",
    "speaker_level_df = pd.read_csv(DATA_PATH + 'r_012_train(combined).csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_concat = 5\n",
    "augmented_td = audio_augment_by_label(word_level_df, speaker_level_df, 0, num_concat,10000)\n",
    "augmented_ssd = audio_augment_by_label(word_level_df, speaker_level_df, 1, num_concat,20000)\n",
    "\n",
    "train_augmented_df = pd.concat([augmented_td, augmented_ssd], ignore_index=True) # combine two csv's\n",
    "train_augmented_df.to_csv(DATA_PATH + f'r_012_train(augmented_{num_concat}).csv',index=False) # creates the augmented train csv in data folder\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
