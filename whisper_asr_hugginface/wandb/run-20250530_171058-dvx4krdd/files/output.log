/home/selinawisco/anaconda3/envs/asr/lib/python3.10/site-packages/accelerate/accelerator.py:451: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead:
dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)
  warnings.warn(
                                                                                                                                   
{'loss': 2.1734, 'grad_norm': 19.89700698852539, 'learning_rate': 1.1999999999999999e-05, 'epoch': 0.05}
{'loss': 0.5868, 'grad_norm': 12.174898147583008, 'learning_rate': 2.6999999999999996e-05, 'epoch': 0.09}
{'loss': 0.3474, 'grad_norm': 11.191818237304688, 'learning_rate': 4.2e-05, 'epoch': 0.14}
{'loss': 0.3061, 'grad_norm': 7.772707939147949, 'learning_rate': 5.6999999999999996e-05, 'epoch': 0.19}
{'loss': 0.292, 'grad_norm': 6.7337117195129395, 'learning_rate': 7.199999999999999e-05, 'epoch': 0.24}
{'loss': 0.3034, 'grad_norm': 10.684733390808105, 'learning_rate': 8.699999999999999e-05, 'epoch': 0.28}
{'loss': 0.2919, 'grad_norm': 15.151809692382812, 'learning_rate': 0.000102, 'epoch': 0.33}
{'loss': 0.2784, 'grad_norm': 9.67324161529541, 'learning_rate': 0.000117, 'epoch': 0.38}
{'loss': 0.2863, 'grad_norm': 5.916483402252197, 'learning_rate': 0.00013199999999999998, 'epoch': 0.42}
{'loss': 0.3103, 'grad_norm': 7.433010578155518, 'learning_rate': 0.000147, 'epoch': 0.47}
{'loss': 0.2845, 'grad_norm': 10.166851043701172, 'learning_rate': 0.000162, 'epoch': 0.52}
{'loss': 0.2744, 'grad_norm': 8.818239212036133, 'learning_rate': 0.00017699999999999997, 'epoch': 0.57}
{'loss': 0.3332, 'grad_norm': 7.541596412658691, 'learning_rate': 0.00019199999999999998, 'epoch': 0.61}
{'loss': 3.2933, 'grad_norm': 18.599414825439453, 'learning_rate': 0.0002058, 'epoch': 0.66}
{'loss': 0.852, 'grad_norm': 11.146780967712402, 'learning_rate': 0.00022079999999999997, 'epoch': 0.71}
{'loss': 0.2956, 'grad_norm': 7.289980411529541, 'learning_rate': 0.00023579999999999999, 'epoch': 0.76}
{'loss': 0.2792, 'grad_norm': 10.59280014038086, 'learning_rate': 0.00025079999999999997, 'epoch': 0.8}
{'loss': 0.3275, 'grad_norm': 10.746763229370117, 'learning_rate': 0.00026579999999999996, 'epoch': 0.85}
{'loss': 0.2827, 'grad_norm': 6.225099563598633, 'learning_rate': 0.0002808, 'epoch': 0.9}
{'loss': 0.316, 'grad_norm': 6.143433094024658, 'learning_rate': 0.0002958, 'epoch': 0.94}
{'loss': 0.2876, 'grad_norm': 9.754717826843262, 'learning_rate': 0.0002988, 'epoch': 0.99}
{'loss': 0.2717, 'grad_norm': 7.955484867095947, 'learning_rate': 0.0002971333333333333, 'epoch': 1.04}
{'loss': 0.2598, 'grad_norm': 9.510849952697754, 'learning_rate': 0.0002954666666666667, 'epoch': 1.09}
{'loss': 0.2483, 'grad_norm': 7.222959995269775, 'learning_rate': 0.00029379999999999993, 'epoch': 1.13}
{'loss': 0.2574, 'grad_norm': 7.289484024047852, 'learning_rate': 0.0002921333333333333, 'epoch': 1.18}
{'loss': 0.2588, 'grad_norm': 3.8467390537261963, 'learning_rate': 0.00029046666666666666, 'epoch': 1.23}
{'loss': 0.2709, 'grad_norm': 9.791406631469727, 'learning_rate': 0.00028879999999999997, 'epoch': 1.27}
{'loss': 0.2345, 'grad_norm': 4.652083396911621, 'learning_rate': 0.00028713333333333334, 'epoch': 1.32}
{'loss': 0.2615, 'grad_norm': 4.554305553436279, 'learning_rate': 0.00028546666666666665, 'epoch': 1.37}
{'loss': 0.2511, 'grad_norm': 5.734495162963867, 'learning_rate': 0.00028379999999999996, 'epoch': 1.42}
{'loss': 0.24, 'grad_norm': 5.665655136108398, 'learning_rate': 0.0002821333333333333, 'epoch': 1.46}
{'loss': 0.2464, 'grad_norm': 5.234738826751709, 'learning_rate': 0.00028046666666666664, 'epoch': 1.51}
{'loss': 0.2478, 'grad_norm': 3.558319568634033, 'learning_rate': 0.0002788, 'epoch': 1.56}
{'loss': 0.2348, 'grad_norm': 6.21186637878418, 'learning_rate': 0.0002771333333333333, 'epoch': 1.61}
{'loss': 0.2272, 'grad_norm': 7.321057319641113, 'learning_rate': 0.0002754666666666667, 'epoch': 1.65}
{'loss': 0.2444, 'grad_norm': 4.280905246734619, 'learning_rate': 0.0002738, 'epoch': 1.7}
{'loss': 0.2181, 'grad_norm': 3.6722187995910645, 'learning_rate': 0.0002721333333333333, 'epoch': 1.75}
{'loss': 0.2311, 'grad_norm': 4.75925350189209, 'learning_rate': 0.00027046666666666666, 'epoch': 1.79}
{'loss': 0.2343, 'grad_norm': 7.594781875610352, 'learning_rate': 0.0002688, 'epoch': 1.84}
{'loss': 0.2132, 'grad_norm': 4.565364360809326, 'learning_rate': 0.00026713333333333334, 'epoch': 1.89}
  File "/home/selinawisco/children_ssd_detection/whisper_asr_hugginface/0.multitask_whisper_asr_finetuning.py", line 237, in <module>
    trainer.train()
  File "/home/selinawisco/anaconda3/envs/asr/lib/python3.10/site-packages/transformers/trainer.py", line 1624, in train
    return inner_training_loop(
  File "/home/selinawisco/anaconda3/envs/asr/lib/python3.10/site-packages/transformers/trainer.py", line 2029, in _inner_training_loop
    self._maybe_log_save_evaluate(tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval)
  File "/home/selinawisco/anaconda3/envs/asr/lib/python3.10/site-packages/transformers/trainer.py", line 2412, in _maybe_log_save_evaluate
    metrics = self.evaluate(ignore_keys=ignore_keys_for_eval)
  File "/home/selinawisco/anaconda3/envs/asr/lib/python3.10/site-packages/transformers/trainer_seq2seq.py", line 166, in evaluate
    return super().evaluate(eval_dataset, ignore_keys=ignore_keys, metric_key_prefix=metric_key_prefix)
  File "/home/selinawisco/anaconda3/envs/asr/lib/python3.10/site-packages/transformers/trainer.py", line 3229, in evaluate
    output = eval_loop(
  File "/home/selinawisco/anaconda3/envs/asr/lib/python3.10/site-packages/transformers/trainer.py", line 3440, in evaluation_loop
    logits = self.accelerator.pad_across_processes(logits, dim=1, pad_index=-100)
  File "/home/selinawisco/anaconda3/envs/asr/lib/python3.10/site-packages/accelerate/accelerator.py", line 2507, in pad_across_processes
    return pad_across_processes(tensor, dim=dim, pad_index=pad_index, pad_first=pad_first)
  File "/home/selinawisco/anaconda3/envs/asr/lib/python3.10/site-packages/accelerate/utils/operations.py", line 411, in wrapper
    return function(*args, **kwargs)
  File "/home/selinawisco/anaconda3/envs/asr/lib/python3.10/site-packages/accelerate/utils/operations.py", line 678, in pad_across_processes
    return recursively_apply(
  File "/home/selinawisco/anaconda3/envs/asr/lib/python3.10/site-packages/accelerate/utils/operations.py", line 107, in recursively_apply
    return honor_type(
  File "/home/selinawisco/anaconda3/envs/asr/lib/python3.10/site-packages/accelerate/utils/operations.py", line 81, in honor_type
    return type(obj)(generator)
  File "/home/selinawisco/anaconda3/envs/asr/lib/python3.10/site-packages/accelerate/utils/operations.py", line 110, in <genexpr>
    recursively_apply(
  File "/home/selinawisco/anaconda3/envs/asr/lib/python3.10/site-packages/accelerate/utils/operations.py", line 128, in recursively_apply
    raise TypeError(
TypeError: Unsupported types (<class 'NoneType'>) passed to `_pad_across_processes`. Only nested list/tuple/dicts of objects that are valid for `is_torch_tensor` should be passed.
